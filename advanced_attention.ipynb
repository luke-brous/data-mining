{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c84c0a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook demonstrates advanced attention mechanisms in PyTorch\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ccce9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.nn.Embedding( 4, 8 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d327bd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.1262, -1.0226,  0.7768, -0.1428,  0.9783,  0.9666,  0.9062,  0.1996],\n",
       "        [-0.7170,  0.1437, -0.2646, -0.4451, -0.6696,  0.2475, -0.8669, -2.3347],\n",
       "        [-1.6918, -1.4278,  1.4860, -0.1009, -0.2374, -1.1133,  0.3374, -1.0927],\n",
       "        [ 0.4969,  0.2433,  0.1658, -1.3663,  1.5591,  1.7361, -1.3396, -0.2387]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = inputs.weight\n",
    "inputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ee4840f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1262, -1.0226,  0.7768, -0.1428,  0.9783,  0.9666,  0.9062,  0.1996],\n",
       "        [-0.7170,  0.1437, -0.2646, -0.4451, -0.6696,  0.2475, -0.8669, -2.3347],\n",
       "        [-1.6918, -1.4278,  1.4860, -0.1009, -0.2374, -1.1133,  0.3374, -1.0927],\n",
       "        [ 0.4969,  0.2433,  0.1658, -1.3663,  1.5591,  1.7361, -1.3396, -0.2387]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = inputs.data\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee9bd8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set dimensions\n",
    "d_in = 8\n",
    "d_out = 6\n",
    "# create weight matrices\n",
    "W_q = torch.nn.Parameter( torch.randn( (d_in, d_out), requires_grad=False ) )\n",
    "W_k = torch.nn.Parameter( torch.randn( (d_in, d_out), requires_grad=False ) )\n",
    "W_v = torch.nn.Parameter( torch.randn( (d_in, d_out), requires_grad=False ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eee23407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.3388, -1.1604,  2.4655,  1.2567,  0.4330, -3.0018],\n",
       "       grad_fn=<SqueezeBackward4>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose an input vector and transform it into our query vector using W_q\n",
    "query = inputs[2] @ W_q\n",
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0350419a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys: tensor([[ 0.6402,  0.0282,  0.8551,  2.3008, -0.4057,  5.1147],\n",
      "        [ 0.2902, -2.0622, -0.6138,  1.2154,  2.8986,  0.1027],\n",
      "        [ 2.7596,  3.5080,  0.9353,  5.3671, -1.2710,  6.7178],\n",
      "        [-0.0876, -5.9122, -1.5527,  2.6520,  5.8264, -0.2949]],\n",
      "       grad_fn=<MmBackward0>)\n",
      "Values: tensor([[-0.7715, -2.0763,  0.0101, -2.1409, -3.2899, -0.9013],\n",
      "        [ 4.2392,  2.7554,  3.9118,  4.4841,  0.8278,  2.2920],\n",
      "        [ 0.0136,  1.9941,  2.0762,  0.7504,  1.7398,  1.9602],\n",
      "        [ 6.8080, -3.3512,  0.2653,  3.0179, -5.1085, -0.2794]],\n",
      "       grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# calculate attention scores using the keys generated by W_k\n",
    "keys = inputs @ W_k\n",
    "values = inputs @ W_v\n",
    "print(\"Keys:\" , keys)\n",
    "print(\"Values:\" , values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "19bb4a66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-12.0596,   2.6752, -22.1900,   9.9778], grad_fn=<SqueezeBackward4>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_scores = query @ keys.T # query is 1 by 6 and keys is 4 by 6 so we need to transpose keys\n",
    "attention_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "50b0af21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.1782e-04, 4.8273e-02, 1.8841e-06, 9.5161e-01],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_weights = torch.softmax( attention_scores / keys.shape[-1]**0.5, dim=-1 ) # the softmax function normalizes the scores\n",
    "attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4a97eedf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0000, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_weights.sum() # ensure the weights sum to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f663f512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6.6831, -3.0563,  0.4413,  3.0880, -4.8217, -0.1553],\n",
       "       grad_fn=<SqueezeBackward4>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_vector = attention_weights @ values # \n",
    "context_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ad8926bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6676af6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleAttention( nn.Module ):\n",
    "    def __init__(self, d_in, d_out):\n",
    "        super().__init__()\n",
    "        #create weight matrices\n",
    "        self.W_q = nn.Parameter( torch.randn( (d_in, d_out), requires_grad=False ) )\n",
    "        self.W_k = nn.Parameter( torch.randn( (d_in, d_out), requires_grad=False ) )\n",
    "        self.W_v = nn.Parameter( torch.randn( (d_in, d_out), requires_grad=False ) )\n",
    "\n",
    "    # x = embedding vectors (inputs)\n",
    "    def forward(self, x):\n",
    "        queries = x @ self.W_q\n",
    "        keys = x @ self.W_k\n",
    "        values = x @ self.W_v\n",
    "        scores = queries @ keys.T\n",
    "        weights = torch.softmax( scores / keys.shape[-1]**0.5, dim = -1 )\n",
    "        context = weights @ values\n",
    "        return context; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a7db99d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use case\n",
    "# instance of the class\n",
    "simple = SimpleAttention( d_in = 8, d_out = 6 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fac967da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 1.3063, -1.1031,  1.4454,  0.5911,  0.0256,  1.5638],\n",
       "        [-0.5855,  1.2256,  0.3116,  0.2306,  1.2067, -0.3640],\n",
       "        [-0.5666, -0.6590, -0.7790,  0.8071, -0.2022, -0.6651],\n",
       "        [ 0.5847, -0.8925, -1.1532,  0.7335, -1.1306,  0.1183],\n",
       "        [ 0.5553,  1.5099, -2.5289,  0.5434, -0.2796, -1.5157],\n",
       "        [ 0.7395, -0.4019, -1.0508, -2.6208,  0.6157,  0.3025],\n",
       "        [-0.0784,  0.0280,  1.2418, -2.1519,  0.7551,  1.1260],\n",
       "        [ 1.3946,  1.5690,  1.7002,  1.8571, -1.6960, -1.5818]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple.W_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eb72a642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2049,  2.6990,  0.5318, -2.4008,  2.2160, -0.4734],\n",
       "        [-0.7376,  3.8528,  0.5971, -2.9316,  3.4040,  0.2830],\n",
       "        [ 0.0285,  3.3906,  0.6603, -2.7588,  2.4408, -0.3328],\n",
       "        [-0.7097,  3.8306,  0.6033, -2.9177,  3.3758,  0.2491]],\n",
       "       grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_vectors = simple( inputs )\n",
    "context_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7f76a929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# second version of the class\n",
    "# it uses nn.Linear to do things more effectively\n",
    "\n",
    "class SimpleAttentionv2( nn.Module ):\n",
    "    def __init__(self, d_in, d_out):\n",
    "        super().__init__()\n",
    "        #create weight matrices\n",
    "        self.W_q = nn.Linear( d_in, d_out, bias=False )\n",
    "        self.W_k = nn.Linear( d_in, d_out, bias=False )\n",
    "        self.W_v = nn.Linear( d_in, d_out, bias=False )\n",
    "\n",
    "\n",
    "    # x = embedding vectors (inputs)\n",
    "    def forward( self, x ):\n",
    "        queries = self.W_q( x )\n",
    "        keys = self.W_k( x )\n",
    "        values = self.W_v( x )\n",
    "        scores = queries @ keys.T\n",
    "        weights = torch.softmax( scores / keys.shape[-1]**0.5, dim = -1 )\n",
    "        context = weights @ values\n",
    "        return context; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "db3cd542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use case\n",
    "# instance of the class\n",
    "simple = SimpleAttentionv2( d_in = 8, d_out = 6 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f7e527f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2415, -0.5311,  0.6949,  0.1416, -0.1356,  0.3026],\n",
       "        [-0.2418, -0.5530,  0.7464,  0.1045, -0.0824,  0.3260],\n",
       "        [-0.2667, -0.5466,  0.7735,  0.0954, -0.0966,  0.3628],\n",
       "        [-0.1930, -0.5313,  0.6326,  0.1641, -0.1389,  0.2315]],\n",
       "       grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_vectors = simple( inputs )\n",
    "context_vectors"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
