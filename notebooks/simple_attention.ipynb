{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f93eaee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98df70ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = \"This is my dog Chico. \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3531f937",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6c7fd1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1212, 318, 616, 3290, 609, 3713, 13, 220]\n"
     ]
    }
   ],
   "source": [
    "enc_text = tokenizer.encode_ordinary( raw_text )\n",
    "print( enc_text )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f05a2fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.1921, -0.7420, -0.3598,  1.5413,  0.0997, -0.3321,  1.2050, -1.7420],\n",
      "        [ 1.1249,  1.9819,  1.3493,  0.9413, -0.1617,  0.3775,  0.5600,  1.0466],\n",
      "        [-0.9652,  0.1160,  1.1386, -1.0232,  1.4958, -0.9316,  0.8884,  0.0799],\n",
      "        [-0.6549,  0.1448, -2.6235, -0.0833, -0.1636,  0.4186,  0.0577,  0.4814]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 4\n",
    "output_dim = 8\n",
    "inputs = torch.nn.Embedding( vocab_size, output_dim )\n",
    "print(inputs.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85d40626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1921, -0.7420, -0.3598,  1.5413,  0.0997, -0.3321,  1.2050, -1.7420],\n",
       "        [ 1.1249,  1.9819,  1.3493,  0.9413, -0.1617,  0.3775,  0.5600,  1.0466],\n",
       "        [-0.9652,  0.1160,  1.1386, -1.0232,  1.4958, -0.9316,  0.8884,  0.0799],\n",
       "        [-0.6549,  0.1448, -2.6235, -0.0833, -0.1636,  0.4186,  0.0577,  0.4814]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = inputs.weight.data\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5b66784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a65879fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.19207634031772614, -0.7419674396514893, -0.35979023575782776, 1.541276216506958, 0.0996936783194542, -0.33205875754356384, 1.2049641609191895, -1.74197518825531]\n",
      "[1.1248893737792969, 1.9819362163543701, 1.349258542060852, 0.941271960735321, -0.16170397400856018, 0.3774888515472412, 0.5599966645240784, 1.0465807914733887]\n",
      "[-0.9651904702186584, 0.11599811911582947, 1.1386221647262573, -1.0231502056121826, 1.495785117149353, -0.9315903782844543, 0.888405978679657, 0.07992368191480637]\n",
      "[-0.6548763513565063, 0.14481131732463837, -2.6235384941101074, -0.08329551666975021, -0.16362157464027405, 0.41856884956359863, 0.057707738131284714, 0.4813976585865021]\n"
     ]
    }
   ],
   "source": [
    "for row in inputs:\n",
    "    print( row.tolist() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f08627da",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1.1,2.3])\n",
    "y = torch.tensor([3.4,-2.1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "698ae2ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-1.0900)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.dot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc358de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.9652,  0.1160,  1.1386, -1.0232,  1.4958, -0.9316,  0.8884,  0.0799])\n"
     ]
    }
   ],
   "source": [
    "query = inputs[2]\n",
    "print( query )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5857bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.8683)\n",
      "tensor(-0.2950)\n",
      "tensor(7.1892)\n",
      "tensor(-2.7981)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(inputs)):\n",
    "    print( torch.dot( query, inputs[i] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a660ea04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.8683, -0.2950,  7.1892, -2.7981])\n"
     ]
    }
   ],
   "source": [
    "attention_scores_2 = torch.zeros(len(inputs)) \n",
    "for i in range( len( inputs ) ):\n",
    "    attention_scores_2[i] = torch.dot( query, inputs[i] )\n",
    "print( attention_scores_2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "639bd6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the attention scores using the softmax function\n",
    "# def softmax(x):\n",
    "#     torch.exp(x) / torch.exp(x).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f702a8bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.1640e-04, 5.6136e-04, 9.9908e-01, 4.5939e-05])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_weights_2 = torch.softmax(attention_scores_2, dim=0)\n",
    "attention_weights_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "514c629e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0000)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_weights_2.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "055486c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.9636,  0.1168,  1.1381, -1.0212,  1.4943, -0.9306,  0.8883,  0.0799])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_vector_2 = torch.zeros( query.shape )\n",
    "for i in range( len( attention_weights_2 ) ):\n",
    "    context_vector_2 += attention_weights_2[i] * inputs[i]\n",
    "context_vector_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "197af71d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7.6990, -1.5790, -0.8683, -0.3420],\n",
       "        [-1.5790,  9.4775, -0.2950, -3.3473],\n",
       "        [-0.8683, -0.2950,  7.1892, -2.7981],\n",
       "        [-0.3420, -3.3473, -2.7981,  7.7768]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all of the attention scores via matrix multiplication\n",
    "attention_scores_2 = inputs @ inputs.T\n",
    "attention_scores_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "079efcf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9.9939e-01, 9.3403e-05, 1.9010e-04, 3.2178e-04],\n",
       "        [1.5783e-05, 9.9992e-01, 5.6993e-05, 2.6929e-06],\n",
       "        [3.1640e-04, 5.6136e-04, 9.9908e-01, 4.5939e-05],\n",
       "        [2.9778e-04, 1.4748e-05, 2.5543e-05, 9.9966e-01]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_weights = torch.softmax(attention_scores_2, dim=-1)\n",
    "attention_weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a837af83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0000)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_weights[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1cc62f56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1917, -0.7413, -0.3601,  1.5402,  0.0998, -0.3319,  1.2045, -1.7407],\n",
       "        [ 1.1248,  1.9818,  1.3492,  0.9412, -0.1616,  0.3774,  0.5600,  1.0465],\n",
       "        [-0.9636,  0.1168,  1.1381, -1.0212,  1.4943, -0.9306,  0.8883,  0.0799],\n",
       "        [-0.6546,  0.1446, -2.6227, -0.0828, -0.1635,  0.4183,  0.0581,  0.4807]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_vectors = attention_weights @ inputs\n",
    "context_vectors"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
