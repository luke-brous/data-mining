{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9df1d182",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import tiktoken\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28ef1f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from gpt_model import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cc89ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version: 2.9.0\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\"torch\"]\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version: {version(p)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aedacaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,    # Vocabulary size\n",
    "    \"context_length\": 1024, # Context length\n",
    "    \"drop_rate\": 0.0,       # Dropout rate\n",
    "    \"qkv_bias\": True        # Query-key-value bias\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "\n",
    "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97768db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"gpt2-small-124M.pth\"\n",
    "# file_name = \"gpt2-medium-355M.pth\"\n",
    "# file_name = \"gpt2-large-774M.pth\"\n",
    "# file_name = \"gpt2-xl-1558M.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10f3cd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "url = f\"https://huggingface.co/rasbt/gpt2-from-scratch-pytorch/resolve/main/{file_name}\"\n",
    "\n",
    "if not os.path.exists(file_name):\n",
    "    response = requests.get(url, timeout=60)\n",
    "    response.raise_for_status()\n",
    "    with open(file_name, \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "    print(f\"Downloaded to {file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fac77860",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llms_from_scratch.ch04 import GPTModel\n",
    "# For llms_from_scratch installation instructions, see:\n",
    "# https://github.com/rasbt/LLMs-from-scratch/tree/main/pkg\n",
    "\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "model.load_state_dict(torch.load(file_name, weights_only=True))\n",
    "model.eval()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7426f1aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you forward.\n",
      "\n",
      "The first step is to understand the importance of your work.\n",
      "\n",
      "The second step is to understand the importance of your work.\n"
     ]
    }
   ],
   "source": [
    "from llms_from_scratch.ch05 import generate, text_to_token_ids, token_ids_to_text\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),\n",
    "    max_new_tokens=30,\n",
    "    context_size=BASE_CONFIG[\"context_length\"],\n",
    "    top_k=1,\n",
    "    temperature=1.0\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf21fc2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 1100\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import requests\n",
    "\n",
    "\n",
    "def download_and_load_file(file_path, url):\n",
    "    if not os.path.exists(file_path):\n",
    "        response = requests.get(url, timeout=30)\n",
    "        response.raise_for_status()\n",
    "        text_data = response.text\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(text_data)\n",
    "\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    return data\n",
    "\n",
    "file_path = \"instruction-data.json\"\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch\"\n",
    "    \"/main/ch07/01_main-chapter-code/instruction-data.json\"\n",
    ")\n",
    "\n",
    "data = download_and_load_file(file_path, url)\n",
    "print(\"Number of entries:\", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf1d6a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example entry:\n",
      " {'instruction': 'Edit the sentence below to remove any redundant words and make it more concise.', 'input': 'I actually think that', 'output': 'I think.'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Example entry:\\n\", data[173])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3fbdceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "\n",
    "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "\n",
    "    return instruction_text + input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39f18cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Identify the correct spelling of the following word.\n",
      "\n",
      "### Input:\n",
      "Ocassion\n",
      "\n",
      "### Response:\n",
      "The correct spelling is 'Occasion.'\n"
     ]
    }
   ],
   "source": [
    "model_input = format_input(data[50])\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[50]['output']}\"\n",
    "\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97fd745e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set length: 935\n",
      "Validation set length: 55\n",
      "Test set length: 110\n"
     ]
    }
   ],
   "source": [
    "train_portion = int(len(data) * 0.85)  # 85% for training\n",
    "test_portion = int(len(data) * 0.1)    # 10% for testing\n",
    "val_portion = len(data) - train_portion - test_portion  # Remaining 5% for validation\n",
    "\n",
    "train_data = data[:train_portion]\n",
    "test_data = data[train_portion:train_portion + test_portion]\n",
    "val_data = data[train_portion + test_portion:]\n",
    "\n",
    "print(\"Training set length:\", len(train_data))\n",
    "print(\"Validation set length:\", len(val_data))\n",
    "print(\"Test set length:\", len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "904927c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class InstructionDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "\n",
    "        # Pre-tokenize texts\n",
    "        self.encoded_texts = []\n",
    "        for entry in data:\n",
    "            instruction_plus_input = format_input(entry)\n",
    "            response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
    "            full_text = instruction_plus_input + response_text\n",
    "            self.encoded_texts.append(\n",
    "                tokenizer.encode(full_text)\n",
    "            )\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.encoded_texts[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31e79505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3cdca52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_fn(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    ignore_index=-100,\n",
    "    allowed_max_length=None,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    # Find the longest sequence in the batch\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "\n",
    "    # Pad and prepare inputs and targets\n",
    "    inputs_lst, targets_lst = [], []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        # Add an <|endoftext|> token\n",
    "        new_item += [pad_token_id]\n",
    "        # Pad sequences to max_length\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] *\n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "        inputs = torch.tensor(padded[:-1])  # Truncate the last token for inputs\n",
    "        targets = torch.tensor(padded[1:])  # Shift +1 to the right for targets\n",
    "\n",
    "        # New: Replace all but the first padding tokens in targets by ignore_index\n",
    "        mask = targets == pad_token_id\n",
    "        indices = torch.nonzero(mask).squeeze()\n",
    "        if indices.numel() > 1:\n",
    "            targets[indices[1:]] = ignore_index\n",
    "\n",
    "        # New: Optionally truncate to maximum sequence length\n",
    "        if allowed_max_length is not None:\n",
    "            inputs = inputs[:allowed_max_length]\n",
    "            targets = targets[:allowed_max_length]\n",
    "\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "\n",
    "    # Convert list of inputs and targets to tensors and transfer to target device\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "\n",
    "    return inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d85d5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_1 = [0, 1, 2, 3, 4]\n",
    "inputs_2 = [5, 6]\n",
    "inputs_3 = [7, 8, 9]\n",
    "\n",
    "batch = (\n",
    "    inputs_1,\n",
    "    inputs_2,\n",
    "    inputs_3\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a27d8c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n",
      "tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256,  -100,  -100,  -100],\n",
      "        [    8,     9, 50256,  -100,  -100]])\n"
     ]
    }
   ],
   "source": [
    "inputs, targets = custom_collate_fn(batch)\n",
    "print(inputs)\n",
    "print(targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4546e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_draft_2(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    # Find the longest sequence in the batch\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "\n",
    "    # Pad and prepare inputs\n",
    "    inputs_lst, targets_lst = [], []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        # Add an <|endoftext|> token\n",
    "        new_item += [pad_token_id]\n",
    "        # Pad sequences to max_length\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] *\n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "        inputs = torch.tensor(padded[:-1])  # Truncate the last token for inputs\n",
    "        targets = torch.tensor(padded[1:])  # Shift +1 to the right for targets\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "\n",
    "    # Convert list of inputs to tensor and transfer to target device\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "    return inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "867ff341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n",
      "tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256, 50256, 50256, 50256],\n",
      "        [    8,     9, 50256, 50256, 50256]])\n"
     ]
    }
   ],
   "source": [
    "inputs, targets = custom_collate_draft_2(batch)\n",
    "print(inputs)\n",
    "print(targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d1fb3fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_fn(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    ignore_index=-100,\n",
    "    allowed_max_length=None,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    # Find the longest sequence in the batch\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "\n",
    "    # Pad and prepare inputs and targets\n",
    "    inputs_lst, targets_lst = [], []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        # Add an <|endoftext|> token\n",
    "        new_item += [pad_token_id]\n",
    "        # Pad sequences to max_length\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] *\n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "        inputs = torch.tensor(padded[:-1])  # Truncate the last token for inputs\n",
    "        targets = torch.tensor(padded[1:])  # Shift +1 to the right for targets\n",
    "\n",
    "        # New: Replace all but the first padding tokens in targets by ignore_index\n",
    "        mask = targets == pad_token_id\n",
    "        indices = torch.nonzero(mask).squeeze()\n",
    "        if indices.numel() > 1:\n",
    "            targets[indices[1:]] = ignore_index\n",
    "\n",
    "        # New: Optionally truncate to maximum sequence length\n",
    "        if allowed_max_length is not None:\n",
    "            inputs = inputs[:allowed_max_length]\n",
    "            targets = targets[:allowed_max_length]\n",
    "\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "\n",
    "    # Convert list of inputs and targets to tensors and transfer to target device\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "\n",
    "    return inputs_tensor, targets_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bb8426dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n",
      "tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256,  -100,  -100,  -100],\n",
      "        [    8,     9, 50256,  -100,  -100]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "inputs, targets = custom_collate_fn(batch)\n",
    "print(inputs)\n",
    "print(targets)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "643c3e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1269)\n"
     ]
    }
   ],
   "source": [
    "logits_1 = torch.tensor(\n",
    "    [[-1.0, 1.0],  # 1st training example\n",
    "     [-0.5, 1.5]]  # 2nd training example\n",
    ")\n",
    "targets_1 = torch.tensor([0, 1])\n",
    "\n",
    "\n",
    "loss_1 = torch.nn.functional.cross_entropy(logits_1, targets_1)\n",
    "print(loss_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e54838d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7936)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "logits_2 = torch.tensor(\n",
    "    [[-1.0, 1.0],\n",
    "     [-0.5, 1.5],\n",
    "     [-0.5, 1.5]]  # New 3rd training example\n",
    ")\n",
    "targets_2 = torch.tensor([0, 1, 1])\n",
    "\n",
    "loss_2 = torch.nn.functional.cross_entropy(logits_2, targets_2)\n",
    "print(loss_2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8435bfcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1269)\n",
      "loss_1 == loss_3: tensor(True)\n"
     ]
    }
   ],
   "source": [
    "targets_3 = torch.tensor([0, 1, -100])\n",
    "\n",
    "loss_3 = torch.nn.functional.cross_entropy(logits_2, targets_3)\n",
    "print(loss_3)\n",
    "print(\"loss_1 == loss_3:\", loss_1 == loss_3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c2ae8565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    # Use PyTorch 2.9 or newer for stable mps results\n",
    "    major, minor = map(int, torch.__version__.split(\".\")[:2])\n",
    "    if (major, minor) >= (2, 9):\n",
    "        device = torch.device(\"mps\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(\"Device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6d149c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_dataset = InstructionDataset(train_data, tokenizer)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=custom_collate_fn,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fa3c7365",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = InstructionDataset(val_data, tokenizer)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=custom_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "test_dataset = InstructionDataset(test_data, tokenizer)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=custom_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8cf4a3ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 79]) torch.Size([8, 79])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 89]) torch.Size([8, 89])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 88]) torch.Size([8, 88])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 87]) torch.Size([8, 87])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 57]) torch.Size([8, 57])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 81]) torch.Size([8, 81])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 82]) torch.Size([8, 82])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 78]) torch.Size([8, 78])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for inputs, targets in train_loader:\n",
    "    print(inputs.shape, targets.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "617f5638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 30003,  6525,   262,  6827,  1262,   257,\n",
      "          985,   576,    13,   198,   198, 21017, 23412,    25,   198,   464,\n",
      "         5156,   318,   845, 13779,    13,   198,   198, 21017, 18261,    25,\n",
      "          198,   464,  5156,   318,   355, 13779,   355,   257,  4936,    13,\n",
      "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256])\n"
     ]
    }
   ],
   "source": [
    "print(inputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4d843460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,   257,\n",
      "         2882,   326, 20431, 32543,   262,  2581,    13,   198,   198, 21017,\n",
      "        46486,    25,   198, 30003,  6525,   262,  6827,  1262,   257,   985,\n",
      "          576,    13,   198,   198, 21017, 23412,    25,   198,   464,  5156,\n",
      "          318,   845, 13779,    13,   198,   198, 21017, 18261,    25,   198,\n",
      "          464,  5156,   318,   355, 13779,   355,   257,  4936,    13, 50256,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100])\n"
     ]
    }
   ],
   "source": [
    "print(targets[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ac3cdb2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-09 22:34:03.962735: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-12-09 22:34:19.939846: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-12-09 22:34:39.313742: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "checkpoint: 100%|██████████| 77.0/77.0 [00:00<00:00, 11.7kiB/s]\n",
      "encoder.json: 100%|██████████| 1.04M/1.04M [00:00<00:00, 1.07MiB/s]\n",
      "hparams.json: 100%|██████████| 91.0/91.0 [00:00<00:00, 16.4kiB/s]\n",
      "model.ckpt.data-00000-of-00001: 100%|██████████| 1.42G/1.42G [12:54<00:00, 1.83MiB/s]\n",
      "model.ckpt.index: 100%|██████████| 10.4k/10.4k [00:00<00:00, 1.49MiB/s]\n",
      "model.ckpt.meta: 100%|██████████| 927k/927k [00:00<00:00, 1.10MiB/s]\n",
      "vocab.bpe: 100%|██████████| 456k/456k [00:00<00:00, 1.77MiB/s]\n"
     ]
    }
   ],
   "source": [
    "from llms_from_scratch.ch04 import GPTModel\n",
    "from llms_from_scratch.ch05 import download_and_load_gpt2, load_weights_into_gpt\n",
    "\n",
    "# from gpt_download import download_and_load_gpt2\n",
    "# from previous_chapters import GPTModel, load_weights_into_gpt\n",
    "# If the `previous_chapters.py` file is not available locally,\n",
    "# you can import it from the `llms-from-scratch` PyPI package.\n",
    "# For details, see: https://github.com/rasbt/LLMs-from-scratch/tree/main/pkg\n",
    "# E.g.,\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"drop_rate\": 0.0,        # Dropout rate\n",
    "    \"qkv_bias\": True         # Query-key-value bias\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "CHOOSE_MODEL = \"gpt2-medium (355M)\"\n",
    "\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "settings, params = download_and_load_gpt2(\n",
    "    model_size=model_size,\n",
    "    models_dir=\"gpt2\"\n",
    ")\n",
    "\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a679a700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "input_text = format_input(val_data[0])\n",
    "print(input_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c9b5f79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from previous_chapters import (\n",
    "    # generate,\n",
    "    # text_to_token_ids,\n",
    "    # token_ids_to_text\n",
    "# )\n",
    "# Alternatively:\n",
    "from llms_from_scratch.ch05 import (\n",
    "   generate,\n",
    "   text_to_token_ids,\n",
    "   token_ids_to_text\n",
    ")\n",
    "\n",
    "\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(input_text, tokenizer),\n",
    "    max_new_tokens=35,\n",
    "    context_size=BASE_CONFIG[\"context_length\"],\n",
    "    eos_id=50256,\n",
    ")\n",
    "generated_text = token_ids_to_text(token_ids, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8280c52a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The chef cooks the meal every day.\n",
      "\n",
      "### Instruction:\n",
      "\n",
      "Convert the active sentence to passive: 'The chef cooks the\n"
     ]
    }
   ],
   "source": [
    "response_text = (\n",
    "    generated_text[len(input_text):]\n",
    "    .replace(\"### Response:\", \"\")\n",
    "    .strip()\n",
    ")\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "56e4c7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llms_from_scratch.ch05 import (\n",
    "   calc_loss_loader,\n",
    "   train_model_simple,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ec5e38b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 3.825896167755127\n",
      "Validation loss: 3.761921215057373\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4fa175a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 2.637, Val loss 2.626\n",
      "Ep 1 (Step 000005): Train loss 1.174, Val loss 1.102\n",
      "Ep 1 (Step 000010): Train loss 0.872, Val loss 0.945\n",
      "Ep 1 (Step 000015): Train loss 0.856, Val loss 0.906\n",
      "Ep 1 (Step 000020): Train loss 0.776, Val loss 0.881\n",
      "Ep 1 (Step 000025): Train loss 0.753, Val loss 0.859\n",
      "Ep 1 (Step 000030): Train loss 0.798, Val loss 0.836\n",
      "Ep 1 (Step 000035): Train loss 0.714, Val loss 0.808\n",
      "Ep 1 (Step 000040): Train loss 0.672, Val loss 0.806\n",
      "Ep 1 (Step 000045): Train loss 0.633, Val loss 0.790\n",
      "Ep 1 (Step 000050): Train loss 0.662, Val loss 0.783\n",
      "Ep 1 (Step 000055): Train loss 0.760, Val loss 0.764\n",
      "Ep 1 (Step 000060): Train loss 0.719, Val loss 0.743\n",
      "Ep 1 (Step 000065): Train loss 0.652, Val loss 0.735\n",
      "Ep 1 (Step 000070): Train loss 0.532, Val loss 0.729\n",
      "Ep 1 (Step 000075): Train loss 0.569, Val loss 0.729\n",
      "Ep 1 (Step 000080): Train loss 0.605, Val loss 0.725\n",
      "Ep 1 (Step 000085): Train loss 0.509, Val loss 0.709\n",
      "Ep 1 (Step 000090): Train loss 0.562, Val loss 0.691\n",
      "Ep 1 (Step 000095): Train loss 0.500, Val loss 0.681\n",
      "Ep 1 (Step 000100): Train loss 0.502, Val loss 0.677\n",
      "Ep 1 (Step 000105): Train loss 0.564, Val loss 0.670\n",
      "Ep 1 (Step 000110): Train loss 0.555, Val loss 0.667\n",
      "Ep 1 (Step 000115): Train loss 0.508, Val loss 0.664\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal is prepared every day by the chef.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive:\n",
      "Ep 2 (Step 000120): Train loss 0.435, Val loss 0.672\n",
      "Ep 2 (Step 000125): Train loss 0.450, Val loss 0.687\n",
      "Ep 2 (Step 000130): Train loss 0.447, Val loss 0.682\n",
      "Ep 2 (Step 000135): Train loss 0.405, Val loss 0.681\n",
      "Ep 2 (Step 000140): Train loss 0.409, Val loss 0.681\n",
      "Ep 2 (Step 000145): Train loss 0.368, Val loss 0.681\n",
      "Ep 2 (Step 000150): Train loss 0.381, Val loss 0.676\n",
      "Ep 2 (Step 000155): Train loss 0.412, Val loss 0.676\n",
      "Ep 2 (Step 000160): Train loss 0.415, Val loss 0.684\n",
      "Ep 2 (Step 000165): Train loss 0.379, Val loss 0.686\n",
      "Ep 2 (Step 000170): Train loss 0.323, Val loss 0.683\n",
      "Ep 2 (Step 000175): Train loss 0.337, Val loss 0.671\n",
      "Ep 2 (Step 000180): Train loss 0.392, Val loss 0.658\n",
      "Ep 2 (Step 000185): Train loss 0.415, Val loss 0.660\n",
      "Ep 2 (Step 000190): Train loss 0.340, Val loss 0.651\n",
      "Ep 2 (Step 000195): Train loss 0.330, Val loss 0.638\n",
      "Ep 2 (Step 000200): Train loss 0.310, Val loss 0.638\n",
      "Ep 2 (Step 000205): Train loss 0.351, Val loss 0.634\n",
      "Ep 2 (Step 000210): Train loss 0.366, Val loss 0.632\n",
      "Ep 2 (Step 000215): Train loss 0.396, Val loss 0.636\n",
      "Ep 2 (Step 000220): Train loss 0.300, Val loss 0.648\n",
      "Ep 2 (Step 000225): Train loss 0.348, Val loss 0.660\n",
      "Ep 2 (Step 000230): Train loss 0.294, Val loss 0.657\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal is cooked every day by the chef.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: What is the capital of the United Kingdom\n",
      "Training completed in 20.36 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00005, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 2\n",
    "\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=format_input(val_data[0]), tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f26c8369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llms_from_scratch.ch05 import plot_losses\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b54a14ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Rewrite the sentence using a simile.\n",
      "\n",
      "### Input:\n",
      "The car is very fast.\n",
      "\n",
      "Correct response:\n",
      ">> The car is as fast as lightning.\n",
      "\n",
      "Model response:\n",
      ">> The car is as fast as a bullet.\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What type of cloud is typically associated with thunderstorms?\n",
      "\n",
      "Correct response:\n",
      ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
      "\n",
      "Model response:\n",
      ">> The type of cloud associated with thunderstorms is a cumulus cloud.\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Name the author of 'Pride and Prejudice'.\n",
      "\n",
      "Correct response:\n",
      ">> Jane Austen.\n",
      "\n",
      "Model response:\n",
      ">> The author of 'Pride and Prejudice' is Jane Austen.\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "\n",
    "for entry in test_data[:3]:\n",
    "\n",
    "    input_text = format_input(entry)\n",
    "\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    response_text = (\n",
    "        generated_text[len(input_text):]\n",
    "        .replace(\"### Response:\", \"\")\n",
    "        .strip()\n",
    ")\n",
    "\n",
    "    print(input_text)\n",
    "    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
    "    print(f\"\\nModel response:\\n>> {response_text.strip()}\")\n",
    "    print(\"-------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c6d27457",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [06:47<00:00,  3.70s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for i, entry in tqdm(enumerate(test_data), total=len(test_data)):\n",
    "\n",
    "    input_text = format_input(entry)\n",
    "\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    response_text = generated_text[len(input_text):].replace(\"### Response:\", \"\").strip()\n",
    "\n",
    "    test_data[i][\"model_response\"] = response_text\n",
    "\n",
    "\n",
    "with open(\"instruction-data-with-response.json\", \"w\") as file:\n",
    "    json.dump(test_data, file, indent=4)  # \"indent\" for pretty-printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a5981e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instruction': 'Rewrite the sentence using a simile.', 'input': 'The car is very fast.', 'output': 'The car is as fast as lightning.', 'model_response': 'The car is as fast as a bullet.'}\n"
     ]
    }
   ],
   "source": [
    "print(test_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ceaad901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as gpt2-medium355M-sft.pth\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "file_name = f\"{re.sub(r'[ ()]', '', CHOOSE_MODEL) }-sft.pth\"\n",
    "torch.save(model.state_dict(), file_name)\n",
    "print(f\"Model saved as {file_name}\")\n",
    "\n",
    "# Load model via\n",
    "# model.load_state_dict(torch.load(\"gpt2-medium355M-sft.pth\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fb65175",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Ollama not running. Launch ollama before proceeding.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     11\u001b[39m ollama_running = check_if_running(\u001b[33m\"\u001b[39m\u001b[33mollama\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ollama_running:\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mOllama not running. Launch ollama before proceeding.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mOllama running:\u001b[39m\u001b[33m\"\u001b[39m, check_if_running(\u001b[33m\"\u001b[39m\u001b[33mollama\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "\u001b[31mRuntimeError\u001b[39m: Ollama not running. Launch ollama before proceeding."
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "\n",
    "def check_if_running(process_name):\n",
    "    running = False\n",
    "    for proc in psutil.process_iter([\"name\"]):\n",
    "        if process_name in proc.info[\"name\"]:\n",
    "            running = True\n",
    "            break\n",
    "    return running\n",
    "\n",
    "ollama_running = check_if_running(\"ollama\")\n",
    "\n",
    "if not ollama_running:\n",
    "    raise RuntimeError(\"Ollama not running. Launch ollama before proceeding.\")\n",
    "print(\"Ollama running:\", check_if_running(\"ollama\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9d2543",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests  # noqa: F811\n",
    "# import urllib.request\n",
    "\n",
    "def query_model(\n",
    "    prompt,\n",
    "    model=\"llama3\",\n",
    "    # If you used OLLAMA_HOST=127.0.0.1:11435 ollama serve\n",
    "    # update the address from 11434 to 11435\n",
    "    url=\"http://localhost:11434/api/chat\"\n",
    "):\n",
    "    # Create the data payload as a dictionary\n",
    "    data = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        \"options\": {     # Settings below are required for deterministic responses\n",
    "            \"seed\": 123,\n",
    "            \"temperature\": 0,\n",
    "            \"num_ctx\": 2048\n",
    "        }\n",
    "    }\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    # Convert the dictionary to a JSON formatted string and encode it to bytes\n",
    "    payload = json.dumps(data).encode(\"utf-8\")\n",
    "\n",
    "    # Create a request object, setting the method to POST and adding necessary headers\n",
    "    request = urllib.request.Request(\n",
    "        url,\n",
    "        data=payload,\n",
    "        method=\"POST\"\n",
    "    )\n",
    "    request.add_header(\"Content-Type\", \"application/json\")\n",
    "\n",
    "    # Send the request and capture the response\n",
    "    response_data = \"\"\n",
    "    with urllib.request.urlopen(request) as response:\n",
    "        # Read and decode the response\n",
    "        while True:\n",
    "            line = response.readline().decode(\"utf-8\")\n",
    "            if not line:\n",
    "                break\n",
    "            response_json = json.loads(line)\n",
    "            response_data += response_json[\"message\"][\"content\"]\n",
    "\n",
    "    return response_data\n",
    "    \"\"\"\n",
    "\n",
    "    # The book originally used the commented-out above, which is based\n",
    "    # on urllib. It works generally fine, but some readers reported\n",
    "    # issues with using urlib when using a (company) VPN.\n",
    "    # The code below uses the requests library, which doesn't seem\n",
    "    # to have these issues.\n",
    "\n",
    "    # Send the POST request\n",
    "    with requests.post(url, json=data, stream=True, timeout=30) as r:\n",
    "        r.raise_for_status()\n",
    "        response_data = \"\"\n",
    "        for line in r.iter_lines(decode_unicode=True):\n",
    "            if not line:\n",
    "                continue\n",
    "            response_json = json.loads(line)\n",
    "            if \"message\" in response_json:\n",
    "                response_data += response_json[\"message\"][\"content\"]\n",
    "\n",
    "    return response_data\n",
    "\n",
    "\n",
    "model = \"llama3\"\n",
    "result = query_model(\"What do Llamas eat?\", model)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62cd7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "for entry in test_data[:3]:\n",
    "    prompt = (\n",
    "        f\"Given the input `{format_input(entry)}` \"\n",
    "        f\"and correct output `{entry['output']}`, \"\n",
    "        f\"score the model response `{entry['model_response']}`\"\n",
    "        f\" on a scale from 0 to 100, where 100 is the best score. \"\n",
    "    )\n",
    "    print(\"\\nDataset response:\")\n",
    "    print(\">>\", entry['output'])\n",
    "    print(\"\\nModel response:\")\n",
    "    print(\">>\", entry[\"model_response\"])\n",
    "    print(\"\\nScore:\")\n",
    "    print(\">>\", query_model(prompt))\n",
    "    print(\"\\n-------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d2d631",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model_scores(json_data, json_key, model=\"llama3\"):\n",
    "    scores = []\n",
    "    for entry in tqdm(json_data, desc=\"Scoring entries\"):\n",
    "        prompt = (\n",
    "            f\"Given the input `{format_input(entry)}` \"\n",
    "            f\"and correct output `{entry['output']}`, \"\n",
    "            f\"score the model response `{entry[json_key]}`\"\n",
    "            f\" on a scale from 0 to 100, where 100 is the best score. \"\n",
    "            f\"Respond with the integer number only.\"\n",
    "        )\n",
    "        score = query_model(prompt, model)\n",
    "        try:\n",
    "            scores.append(int(score))\n",
    "        except ValueError:\n",
    "            print(f\"Could not convert score: {score}\")\n",
    "            continue\n",
    "\n",
    "    return scores\n",
    "\n",
    "\n",
    "scores = generate_model_scores(test_data, \"model_response\")\n",
    "print(f\"Number of scores: {len(scores)} of {len(test_data)}\")\n",
    "print(f\"Average score: {sum(scores)/len(scores):.2f}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
