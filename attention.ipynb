{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f93eaee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98df70ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = \"This is my dog Chico. \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3531f937",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6c7fd1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1212, 318, 616, 3290, 609, 3713, 13, 220]\n"
     ]
    }
   ],
   "source": [
    "enc_text = tokenizer.encode_ordinary( raw_text )\n",
    "print( enc_text )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f05a2fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.2771,  1.2925,  0.4086, -0.2523, -1.1620, -0.6990, -0.6632, -0.5130],\n",
      "        [-0.8811, -0.1949,  0.0994, -0.8223,  0.9215,  0.1530,  0.4579,  0.1149],\n",
      "        [-1.8343, -0.3739, -0.5283,  0.7703,  2.1087, -0.9418, -0.4201,  1.8617],\n",
      "        [ 0.0719, -0.0541,  0.6511, -1.8043,  1.7056,  0.5268,  0.3230,  2.6119]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 4\n",
    "output_dim = 8\n",
    "inputs = torch.nn.Embedding( vocab_size, output_dim )\n",
    "print(inputs.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85d40626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2771,  1.2925,  0.4086, -0.2523, -1.1620, -0.6990, -0.6632, -0.5130],\n",
       "        [-0.8811, -0.1949,  0.0994, -0.8223,  0.9215,  0.1530,  0.4579,  0.1149],\n",
       "        [-1.8343, -0.3739, -0.5283,  0.7703,  2.1087, -0.9418, -0.4201,  1.8617],\n",
       "        [ 0.0719, -0.0541,  0.6511, -1.8043,  1.7056,  0.5268,  0.3230,  2.6119]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = inputs.weight.data\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5b66784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a65879fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2770703136920929, 1.2925260066986084, 0.4085632264614105, -0.2523374557495117, -1.1619651317596436, -0.6990135312080383, -0.663209855556488, -0.51301509141922]\n",
      "[-0.8811240792274475, -0.19490861892700195, 0.09936337918043137, -0.8223011493682861, 0.9215407371520996, 0.15300123393535614, 0.4579039216041565, 0.1148504689335823]\n",
      "[-1.8342560529708862, -0.37388312816619873, -0.5282573699951172, 0.770287811756134, 2.108671188354492, -0.9418469071388245, -0.42011427879333496, 1.8616602420806885]\n",
      "[0.07187089323997498, -0.05407668650150299, 0.6511098742485046, -1.8043287992477417, 1.7055691480636597, 0.5267564654350281, 0.3230374753475189, 2.611872911453247]\n"
     ]
    }
   ],
   "source": [
    "for row in inputs:\n",
    "    print( row.tolist() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f08627da",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1.1,2.3])\n",
    "y = torch.tensor([3.4,-2.1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "698ae2ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-1.0900)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.dot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc358de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.8343, -0.3739, -0.5283,  0.7703,  2.1087, -0.9418, -0.4201,  1.8617])\n"
     ]
    }
   ],
   "source": [
    "query = inputs[2]\n",
    "print( query )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5857bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-3.8699)\n",
      "tensor(2.8237)\n",
      "tensor(13.3525)\n",
      "tensor(5.9817)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(inputs)):\n",
    "    print( torch.dot( query, inputs[i] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a660ea04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-3.8699,  2.8237, 13.3525,  5.9817])\n"
     ]
    }
   ],
   "source": [
    "attention_scores_2 = torch.zeros(len(inputs)) \n",
    "for i in range( len( inputs ) ):\n",
    "    attention_scores_2[i] = torch.dot( query, inputs[i] )\n",
    "print( attention_scores_2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "639bd6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the attention scores using the softmax function\n",
    "# def softmax(x):\n",
    "#     torch.exp(x) / torch.exp(x).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f702a8bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.3120e-08, 2.6738e-05, 9.9934e-01, 6.2890e-04])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_weights_2 = torch.softmax(attention_scores_2, dim=0)\n",
    "attention_weights_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "514c629e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0000)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_weights_2.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055486c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.8330, -0.3737, -0.5275,  0.7686,  2.1084, -0.9409, -0.4196,  1.8621])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_vector_2 = torch.zeros( query.shape )\n",
    "for i in range( len( attention_weights_2 ) ):\n",
    "    context_vector_2 += attention_weights_2[i] * inputs[i]\n",
    "context_vector_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "197af71d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.5198, -1.7883, -3.8699, -3.2329],\n",
       "        [-1.7883,  2.5959,  2.8237,  3.5959],\n",
       "        [-3.8699,  2.8237, 13.3525,  5.9817],\n",
       "        [-3.2329,  3.5959,  5.9817, 13.8003]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all of the attention scores via matrix multiplication\n",
    "attention_scores_2 = inputs @ inputs.T\n",
    "attention_scores_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "079efcf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9.9753e-01, 1.8169e-03, 2.2662e-04, 4.2854e-04],\n",
       "        [2.5013e-03, 2.0055e-01, 2.5186e-01, 5.4510e-01],\n",
       "        [3.3120e-08, 2.6738e-05, 9.9934e-01, 6.2890e-04],\n",
       "        [4.0031e-08, 3.6989e-05, 4.0198e-04, 9.9956e-01]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_weights = torch.softmax(attention_scores_2, dim=-1)\n",
    "attention_weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a837af83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
